\chapter*{Abstract}

Being able to predict the state of benthic habitats based on limited information is crucial for environmental conservation, particularly as the impact of human activity on our oceans is greater than ever before. Prior to the flourishing state of machine learning we see today, creating benthic habitat maps would have been an opinionated and subjective task carried out by experts, based on limited data sampled from habitats. In more recent years, the number of tools which allow convenient application of machine learning to data sets has seen more research carried out in the area of benthic habitat mapping. Many of these such as Support Vector Machines (SVMs) are deterministic, in that predictions at a location, given some input data, strictly provide a single label as its guess, without any information regarding how certain it is. Probabilistic models such as Gaussian processes overcome this and provide predictive variances with predictive means, adding a rich layer of information that represents the confidence of the predictions made. But due to the mathematical steps involved, the time it requires to fit Gaussian processes exceeds practicality beyond several thousand points. To allow the use of this Gaussian processes to scale with large data sets, this study explores the viability of approximation methods in creating habitat maps. The methods mentioned so far only account for bathymetry points corresponding to a single label, despite working with multi-label data, meaning not all the information available is being fully utilised. Dirichlet Multinomial distributions are able to model these multi-label outputs, and the method that is used to exploit the full extent of the class data used in this study.
