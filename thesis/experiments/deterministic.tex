\section{Deterministic Approaches (Single Output)} \label{chapsec:deterministic}

We first briefly review the machine learning techniques more commonly used in benthic habitat mapping first, to get an idea for the sort of maps generated as well as their performance for the given dataset. To quantifiably compare their predictions, we calculate their unweighted f-scores. The \textit{f-score} of predictions are a measure of accuracy in classification problems that takes into account both precision and recall across each possible label, and is calculated by $2*\frac{\text{precision*recall}}{precision+recall}$. The use of unweighted f-scores means, we calculated the \textit{f-score} separately for each label in the predictions, and simply took the average of them. This was chosen in favour of weighted f-scores that provide a larger weight for more frequent labels as the high occurrence of sand would hide the fact that the other labels are constantly incorrectly predicted, if this was the case. 
% Logistic regression has been included here despite containing 'probabilistic` predictions in the form of regression values passed through the \textit{logistic} function, and as such the results displayed are a result of simply taking the argmax over possible the predictive probability over possible for each datapoint. Those probabilistic outputs are useful for comparisons with those of Gaussian Processes, however, which will be explored in the next section. \todo{(this GP-LR comparison hasn't happened yet)}

\begin{table}
    \centering
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Algorithm & 10F-CV F-score & 10F-CV Accuracy & Label type\\\hline
    SVC & 0.21514 & 0.75554 & 4 labels \\
    LogisticRegression & 0.33713 & 0.77001 & 4 labels \\
    KNeighborsClassifier & 0.4714 & 0.7796 & 4 labels \\
    RandomForestClassifier & 0.4737 & 0.79406 & 4 labels \\
    SVC & 0.10355 & 0.29408 & 24 labels \\
    LogisticRegression & 0.13335 & 0.31389 & 24 labels \\
    KNeighborsClassifier & 0.22593 & 0.33093 & 24 labels \\
    RandomForestClassifier & 0.22015 & 0.3405 & 24 labels \\
    \hline
\end{tabular}
\label{table:detresults}
    \caption{Performance of common machine learning models}
\end{table}

While the accuracy of the Logistic Regressor, kNN, and Random Forest Classifier are reasonable (above $0.75$), the former two's f1-scores are very poor at $0.33$, with the latter two at just below $0.5$, which is an equally undesirable result. Looking at the ratio of available labels in the downsampled data in the 4-label case ($232,  470,  446, 3548$ for labels 0, 1, 2, 3 respectively) reveals that label 3 accounts for $0.7556$ of the dataset - a value very close to the accuracy of predict. The weighted f1-score of a `naive' classifier that always predicts label 3 has an accuracy of  $0.75554$ and an average f-score of $0.215$ - highlighting the fact that these simpler models are not able to produce results that confidently outperform simply guessing one label for any given datapoint. \Cref{fig:det4maps} visualises the predictions from \Cref{table:detresults} on the full query data for the 4 and 24-label data respectively. The Support Vector Machines (SVM) that generally provides moderately respectable real-world performance has noticably failed to predict anything other than sand throughout the query space, hinting the underlying data has complexities that require more complex models to explain it. The predictive maps generate using Logistic Regression and kNN bear noticable similarities in many areas of the map, while Random Forests identified regions that the others didn't. 

\begin{figure}[H]
    \includegraphics[scale=0.61]{det4_preds.pdf}
    \includegraphics[scale=0.45]{det4_preds_colourbar.pdf}
    \caption{Full aggregated label predictive map using SVMs, Logistic Regression, kNN, and Random Forests}
    \label{fig:det4maps}
\end{figure}

\begin{figure}[H]
    \includegraphics[scale=0.61]{det24_preds.pdf}
    \includegraphics[scale=0.45]{det24_preds_colourbar.pdf}
    \caption{Full predictive map using SVMs, Logistic Regression, kNN, and Random Forests}
    \label{fig:det24maps}
\end{figure}

The maps in \Cref{fig:det4maps} (with the exception of the SVM-generated one) provide some insight into where certain habitats occur in Scott Reef. However, as the results of the other three models were comparable, particularly for Random Forests and K-Nearest Neighbours, it is not obvious which one is more `trustworthy', and what prediction to take in areas that they disagree on. One piece of information that can aid in this regard is if a level of \textit{confidence}, which we explore in the next section.

