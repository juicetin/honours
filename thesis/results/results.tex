\chapter{Results} \label{chap:results}

The results from the Experiments detailed in Chapter 4 are listed below. The range of possible class values in some cases have been stretched beyond the existing class labels so that values align between different outputs to allow for easy, direct visual comparison. Note that the results to the above experiments will include those of both non-downsampled and downsampled results, as well as the full set of 24 labels as well as simplified ones.

Due to the low occurrence of some labels in the original dataset though, they have ended up being ommitted in predictions - these are excluded from the colour schemes of the benthic maps generated, so that those that do occur can be given more distinct colours from one another as to better differentiate between the habitats of a map, as well as allow a consistent comparison of across different maps.

In this section, the performance of common machine learning algorithms, namely kNN, Logistic Regression, Random Forest, and SVM are explored first, to provide a comparison to the later, more complex algorithms.

% The associated generated maps from the experiments are also provided here, but proper evaluation of them, such as what habitat clusters and relationships can be gleaned, will be explored in Chapter 5. 

\pagebreak
\section{Deterministic Methods}

\todo{results here currently outperform the argmax of GPs and DMs...hmm}

\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Algorithm & 10F-CV F1 & 10F-CV Accuracy & Parameters & Data \\\hline
        KNN         &  0.7180212553324016  &  0.8752880347998457 &   n = 5  & simple labels \\
Logistic Regression &  0.21221134330881872 &  0.7374253253308372 &            & simple labels \\
   Random Forest    &  0.8103659316744121  &  0.9117076519281244 &            & simple labels \\
        SVC         &  0.21221261743619468 &  0.7374255088743278 &     OvA    & simple labels \\
         DM         &   0.287405310254214  &  0.757925654489819  &            & simple labels \\
        KNN         &  0.4711662374785644  &  0.6510716003156948 &   n = 5  &  full labels  \\
Logistic Regression &  0.06457891531653175 & 0.25912130389295746 &            &  full labels  \\
   Random Forest    &  0.6075895500970125  &  0.7263355175008718 &            &  full labels  \\
        SVC         & 0.012413092166172946 & 0.16549499843988033 &     OvA    &  full labels  \\
         DM         &  0.13802716811804644 & 0.37856057852908254 &            &  full labels  \\
    \hline
\end{tabular}

\section{Gaussian Process Classification}

\todo{transfer all the results from markdown}

\todo{show more stratified results (not just even split) to show that even splits did better}

\begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    500     & Even       & GP     & 10F-CV & 10        & 0.86534    &                     &         \\
    500     & Stratified & GP     & 10F-CV & 10        & 0.80136    &                     &         \\
    1000    & Even       & GP     & All    & 1         & 0.87626    & Deterministic       & 0.56208 \\
    1000    & Even       & PoEGP  & All    & 5         & 0.80973    &                     & 0.47481 \\
    1000    & Even       & PoEGP  & All    & 200       & 0.80186    &                     & 0.47595 \\
    1000    & Even       & GPoEGP & All    & 5         & 0.80864    &                     & 0.51018 \\
    1000    & Even       & GPoEGP & All    & 200       & 0.80105    &                     & 0.47748 \\
    1000    & Even       & BCM    & All    & 5         & 0.80682    &                     & 0.48167 \\
    1000    & Even       & BCM    & All    & 200       & 0.80421    &                     & 0.48227 \\
    1000    & Even       & GPy    & All    & 1         & 0.87638    & RBF, EP (default)   & 0.57013 \\
    \hline
\end{tabular}

\todo{highlight areas with low/high certainty, etc.}

\section{Dirichlet Multinomial Regression}

\todo{transfer all the results from markdown}
Success: True, final objective = 3913.8572360999738.
0.199794976896
Success: True, final objective = 3927.5321104690765.
0.192835558564
Success: True, final objective = 3925.9034987284517.
0.195386663189
Success: True, final objective = 3879.9722475717376.
0.203971406818
Success: True, final objective = 3908.6004550069883.
0.197255577737
Success: True, final objective = 3915.3513496785285.
0.199563666814
Success: True, final objective = 3903.6599254078446.
0.199662834998
Success: True, final objective = 3914.487254186762.
0.197538693463
Success: True, final objective = 3934.1967907157946.
0.190080656617
Success: True, final objective = 3938.2977172382407.
0.193515492187
Average error was 0.19696055272835952

\begin{figure}[H]
    \begin{minipage}{.45\linewidth}
        \centerline{\includegraphics[scale=0.62]{dm_simplelabel_heatmap_0.pdf}}
        \caption{label 0}
        \label{fig:dm_sl_hm_0}
    \end{minipage}
    \hfill
    \begin{minipage}{.45\linewidth}
        \includegraphics[scale=0.62]{dm_simplelabel_heatmap_1.pdf}
        \caption{label 1}
        \label{fig:dm_sl_hm_1}
    \end{minipage}
    \begin{minipage}{.45\linewidth}
        \centerline{\includegraphics[scale=0.62]{dm_simplelabel_heatmap_2.pdf}}
        \caption{label 2}
        \label{fig:dm_sl_hm_2}
    \end{minipage}
    \hfill
    \begin{minipage}{.45\linewidth}
        \includegraphics[scale=0.62]{dm_simplelabel_heatmap_3.pdf}
        \caption{label 3}
        \label{fig:dm_sl_hm_3}
    \end{minipage}

    \todo{fix the bar legends here}
\end{figure}

In the simple case where the labels are summarised down to just the basic four, 

\todo{highlight areas with biodiversity, etc.}
