\section{Multi-Output Predictions} \label{chapsec:dm}

Looking at the deterministic maps from \Cref{fig:det4maps} as well as \Cref{fig:gpogpe4} and \Cref{fig:gpogpe23} using the simplified ensemble Gaussian process approximations, it can be observed where clusters of certain habitats are - but what can't be easily obtained, or at least automated without non-trivial extra effort, is identifying exactly \textit{where} these clusters are, and the frequency of co-occurrence between the different habitats. This is a consequence of only having a single label per point, but considering the area covered by a single data point, it is unrealistic to imagine the entire surface being only a \textit{single} label. Thus, we explore how to predict the \textbf{distribution} of labels at each point as represented in the original data, to provide richer habitat maps that naturally illustrate the co-occurrence of different habitats.

As a means of effectively visualising the separate labels, we need to look at the normalised distribution of habitat classes for each label separately. In the maps below created from each model's respective predictions, each class is represented on a separate heatmap, with the occurence (with a maximum of $1$, when an area is predicted to \textit{only} contain that label) indicated by the colour bars included above each map. This allows initial observations to be made of where certain labels are more abundant than others. This representation allows a user/viewer to easily manually identify where and which labels have a high occurrence (without being required to constantly check which specific colour a label was, etc.), but also larger areas where habitats co-occur.

% \subsection{Coercion of Common Regression Machine Learning Algorithms} \label{ss:commonMLcoercion}
% To do this, we first look at the regression version of algorithms used in the previous section, instead applied individually to each of the label distribution values in the original dataset, rather than simplifying them down to a single habitat label. 
% 
% \begin{table}[H]
%     \centering
%     \title{\large{\textbf{Multi-output average Errors}}}
%     \begin{tabular}{|c|C{2cm}|C{2cm}|C{2cm}|C{2cm}|C{2cm}|}
%         \hline
%         Algorithm & Average Error & Labels Used & Average Row Sum* & Min Row Sum & Max Row Sum\\\hline
%         SVR & 0.2073 & 4 & 0.7407 & 0.1687 & 1.4418\\
%         LinearRegression & 0.1827 & 4 & 0.5224 & 0.1136 & 0.8421\\
%         KNeighborsRegressor & 0.1698 & 4 & 0.5365 & 0.0 & 1.0\\
%         RandomForestRegressor & 0.1722 & 4 & 0.5267 & 0.0 & 1.4\\
%         SVR & 0.0983 & 24 & 1.8567 & 1.826 & 1.8834\\
%         LinearRegression & 0.0463 & 24 & 0.155 & -0.1624 & 0.4006\\
%         KNeighborsRegressor & 0.0434 & 24 & 0.1655 & 0.0 & 1.0\\
%         RandomForestRegressor & 0.0441 & 24 & 0.1842 & 0.0 & 1.3\\
%         \hline
%     \end{tabular}
%     \label{table:dmbasicresults}
%     \caption{Average errors of multi-output versions of single-output regression methods}
% \end{table}
% 
% Note that the smaller errors when predicting using all 24-labels do not mean that it is `better' to do so - because the values in the training set are smaller to begin with, it follows that the variance in predictions will also be smaller as a result. To visualise how these results translate when each of the models' trained parameters are used to predict the labels over the query space, heatmaps of each label were used, to allow easy identification of information such as which areas are particularly domianted by a single habitat, where they are particularly scarce, or areas where multiple habitats co-exist. Full predictions using SVM Regression was ommitted largely due to its poor performance observed from the average error above, in addition to the extensive computational time required for predictions compared to the other three algorithms.
% 
% \begin{figure}[H]
%     \title{\large{\textbf{Linear Regression}}}
%     \centerline{\includegraphics[scale=0.85]{multioutput_distr_colourbar.pdf}}
%     \centerline{\includegraphics[scale=0.85]{multi4_preds_lr.pdf}}
%     \caption{Map of full query Linear Regression 4-label predictions}
%     \label{fig:multi4_lr}
% \end{figure}
% 
% It is immediately apparent that while linear regression has an average error within reason, the maps generated are likely faulty - each label's distribution is almost consistent throughout the $200$km-squared area, a uniformity that is highly improbable if not impossible, given the large area of benthos covered. Moreover, the sum of the normalised predictive distributions at most points sum to almost $2$ - well beyond the expected value, $1$.
% 
% \begin{figure}[H]
%     \title{\large{\textbf{K Nearest Neighbour Regression}}}
%     \centerline{\includegraphics[scale=0.85]{multioutput_distr_colourbar.pdf}}
%     \centerline{\includegraphics[scale=0.75]{multi4_preds_knn.pdf}}
%     \caption{Map of full query K Nearest Neighbour Regression 4-label predictions}
%     \label{fig:multi4_rf}
% \end{figure}
% 
% K-Nearest Neighbour performs slightly better, as there are actually visible differences in the distribution of label 3 throughout the area, whilst showing traces of the other three labels. However, the failure for label distributions per point can be easily observed here, considering that a sizable portion of label 3 areas occur at roughtly a $0.5$ rate, but the combination of other labels in the same space quite clearly don't make up the remaining $0.5$, as they mostly sit near the $0.0$ mark. Moreover, the predictions themselves are very noisy - there are no observable contiguous areas where the occurrence of a habitat occurs at a similar rate, and nor are there visible smooth transitions where a habitat goes from high to low density.
% 
% \begin{figure}[H]
%     \title{\large{\textbf{SVM Regression}}}
%     \centerline{\includegraphics[scale=0.85]{multioutput_distr_colourbar.pdf}}
%     \centerline{\includegraphics[scale=0.85]{multi4_preds_svm.pdf}}
%     \caption{Map of full query SVM Regression 4-label predictions}
%     \label{fig:multi4_svr}
% \end{figure}
% 
% SVM Regression is able to provide more reasonable predictions showing distinct areas of specific habitats that are more `natural' compared to Logistic Regression and K-NN regression thus far. However, considering the rarity of labels $0$ and $1$ in the original data, it is quite unrealistic that they could be almost uniformly present throughout the entire of Scott Reef at such a high rate. Again, visual inspection indicates that a large portion of the map has violated the constraints of the normalised label distributions summing back up to $1$ at each datapoint.
% 
% \begin{figure}[H]
%     \title{\large{\textbf{Random Forest Regression}}}
%     \centerline{\includegraphics[scale=0.85]{multioutput_distr_colourbar.pdf}}
%     \centerline{\includegraphics[scale=0.85]{multi4_preds_rf.pdf}}
%     \caption{Map of full query Random Forest Regression 4-label predictions}
%     \label{fig:multi4_rf}
% \end{figure}
% 
% Random Forest Regression produces a similarly varied map, but very different to that of KNN and SVM regression in some key areas. Labels 1, 2, and 3 have a notably higher predicted occurence rate throughout Scott Reef, with visible swaths that outweigh label $4$ in the region. Without marine biologist expert or similar input, however, it is hard to determine whether the large regions of the less common habitats predicted by the Random Forest Regressor are likely in a location such as Scott Reef.
% 
% As a result of the constraint requiring label distributions per point to sum to $1$, the above use of independent regressors is more of an illustrative exercise than one that can be relied on for real-world use - even if some of the information it provides appears to be of some use. In the extreme cases, some coordinates had no labels at all (the distribtions `summed' to $0$), while others were as high as $3$. These suffer from the same disadvantage as in the previous section on single-output predictions by stating predictions in absolutes rather than providing confidence levels - and again, we apply Gaussian Processes to the problem to attempt to alleviate this, but using regression this time around.
% 
% \subsection{Coercion of Gaussian Process Regression}
% Although a Gaussian Process is only designed to deal with single outputs, each of the label distributions per datapoint are seperate values, meaning it is possible to use multiple Gaussian Processes to allow it to work as a multi-output model. Morever, compared to the previous coercion of deterministic methods, we can use the variance of the Gaussian Process over each label to visualise the uncertainty of predictions. In contrast to previous methods however, due to the established $O(n^3)$ complexity, it was impractical to perform 10-fold cross validation on the full $\geq 5000$ data points in the downsampled training set. Instead, a method similar to \todo{argmax, 230 points per class, 920 total, randomly sample the 920 until predictions on remaining points gives best performance} was used to select the training points.
% 
% % Average error was $0.14409166865082482$ in 10-fold CV \todo{(format)}
% \begin{table}[H]
%     \centering
%     \begin{tabular}{|c|c|}
%         \hline
%         Labels used & Root Mean Squared Error \\\hline
%         4 & 0.14409\\
%         24  & ? \\
%         \hline
%     \end{tabular}
%     \label{table:gpmbasicresults}
%     \caption{Multiple Gaussian Process Regression average error for the two label sets}
% \end{table}
% 
% \Cref{fig:gpm4_simple_preds} below shows the full predictions for the 4-label dataset, with the majority of predictions for labels $0$, $1$, and $2$ lying in the range $[0.1, 0.2]$. This is a likely indicator that the model and its parameters are inappropriate for the problem at hand, despite the variability of label 3 providing a more reasonable prediction of its occurrence. Looking at the actual predicted values, however, reveals how far they have deviated from summing to $1$ per point - \todo{waiting for another prediction to finish to pull values back up}.
% 
% % While the ability of a Gaussian Process allows the data to `speak for itself' aided in bringing the average sum of distributions per point to $1$ compared to the simpler models in \ref{ss:commonMLcoercion}, this property is still not inherently there, not to mention that the full query dataset of just under $3,000,000$ points was too computational intensive to perform full predictions on.
% 
% \begin{figure}[H]
%     \centering
%     \includegraphics[scale=0.85]{gp4_mp_allpreds_colourbar.pdf}
%     \includegraphics[scale=0.85]{gp4_mp_allpreds.pdf}
%     \label{fig:gpm4_simple_preds}
%     \caption{Gaussian Process predictions on full query data}
% \end{figure}
% 
% Since multiple Gaussian Process Classification (Regression) does not discard a majority of the data compared to single-label Gaussian Process Classification, observing the variance is now more meaningful as \textit{each } each of the possible $c$ classes has a probability and corresponding variance of occurrence. However, as we see in \Cref{fig:gpm4_simple_vars}, not much can be gained from the 4-label case, considering that labels 0, 1, 2 have almost no variance, with only label 3 contaiing any visible sections with variance higher than $0.13$, going as high as $0.41$. Given that none of the methods so far are able to simultaneously (at least mostly) adhere to the constraints of the Dirichlet Distribution without explicitly incorporating it or provide realistic predictions given the rich habitat distribution data, we turn to a model that can in theory do both.
% 
% \begin{figure}[H]
%     \centering
%     \includegraphics[scale=0.85]{gp4_mp_vars_all_colourbar.pdf}
%     \includegraphics[scale=0.85]{gp4_mp_vars_all.pdf}
%     \label{fig:gpm4_simple_vars}
%     \caption{Gaussian Process variances on full query data}
% \end{figure}
% 

\subsection{Dirichlet Multinomial Regression}

The last model used was the Dirichlet Multinomial, which incorporates the constraint where predictions over any number of labels had to sum back to $1$, as a result of the Dirichlet distribution component. This means that from a mathematical standpoint, these predictions will be more `correct' for multi-output labels than all the previosly explored models - but we also want to see how they hold up in practice.

To assess initial performance, the weights and hence the $\alpha$ parameter was obtained via the maximum a posteriori estimation.

% \begin{tabular}{|c|c|c|c|c|c|}
%     \hline
%     Algorithm & 10F-CV F1 & 10F-CV Accuracy & Parameters & Data \\\hline
%          DM         &  0.13802716811804644 & 0.37856057852908254 &            &  full labels  \\
%          DM         &   0.287405310254214  &  0.757925654489819  &            & simple labels \\ %     \hline
% \end{tabular}

\begin{table}
    \centering
    \begin{tabular}{|c|c|}
        \hline
        Labels used & Root Mean Squared Error \\\hline
        4 & 0.17664\\
        24  & 0.05916\\
        \hline
    \end{tabular}
    \label{table:dmbasicresults}
    \caption{Dirichlet Multinomial Regression average error for the two label sets}
\end{table}

\begin{figure}
    \begin{minipage}{\linewidth}
        \centerline{\includegraphics[scale=0.85]{dm_standalone_colorbar.pdf}}
        \centerline{\includegraphics[scale=0.85]{dm_simplelabel_heatmaps.pdf}}
        \caption{Distribution heatmaps over each label (in the simple 4-label case) for Dirichlet Multinomial Regressor output on query points}
        \label{fig:dm_4label_heatmap}
    \end{minipage}
    \hfill
\end{figure}

For the simplified labels, we can see some similarities with the models generated using random forests and Gaussian processes (\Cref{fig:det4preds}, \Cref{fig:gpogpe}),  with certain regions matching up to different predictions. For example, all predictions were able to agree on the general dominance of label 3 throughout the reef, but due to the single-output nature of the previous methods, this dominance also meant it was the \textit{only} label to appear in a majority of the predictive maps. Using this model, the actual occupancy rate of label 3 can be determined, instead of only being able to see `all sand'.The ability to quantify the presence of certain habitats also becomes quite trivial, as a single line of Python code can provide information such as label 3 occurring at a rate of more than $0.5$ in $73\%$ of the predicted query space, whereas labels $0$, $1$, and $2$ only occur at a similar rate $4.7\%$, $9.9\%$, and $2.3\%$ of the time.

Using the Dirichlet multinomial that makes full use of the original multi-label data, more detailed observations can also be made regarding the confidence of the multi-output predictions made, by observing the entropy of the Dirichlet distribution using the $\alpha$ parameter \todo{(cite equation)}. Low entropy areas indicate a low variance in the data and hence a confidence in the predictions made in that area, with the reverse being true for high-entropy areas. \Cref{fig:dm4_entropy} shows some key regions (in dark blue) that are very low entropy, with large regions of moderate entropy (cyan) predictions spread out over the query space. Of note is the fact that the noticable areas of co-habitation between labels $1$ and $3$ where they are close to an even $50:50$ split are very low entropy, highlighting the Dirichlet multinomial's ability to detect when a subset of labels within multi-output data correlate with one another with confidence.

\begin{figure}[H]
    \begin{minipage}{\linewidth}
        \centerline{\includegraphics[scale=0.9]{dm4_entropy_map.pdf}}
        \caption{Entropy plot over all query points for the simplified labels}
        \label{fig:dm4_entropy}
    \end{minipage}
    \hfill
\end{figure}

\todo{(does this go here?)}
What becomes apparent is that in the areas where the DM is confident of a mix of certain set of predominant labels, the GP is instead equally uncertain of each of them with a considerably higher variance, which is misleading information when taken at face value. For example, this sort of uncertainty may be taken into consideration purposes, where autonomous vehicles are used to collect data, or in making decisions with regards to conservation efforts. In the first scenario, resources are being wasted on areas where models such as the DM can be confident of a particular distribution of labels, whereas in the second, important conservation actions may be withheld if the \textit{certainty} of information is brought into question. For example, in an area that contains a particular mix of coral and bleached coral, a DM has the potential to make a confident prediction of their coexistence, whereas a GP would make predictions where their respective probabilities in a one-vs-all classifier may be close to their distribution in the area, but have a high noise factor.

% \todo{summarise and plot the variances here}
\subsection{Dirichlet Multinomial Predictive Map Variance}

As the above results from Dirichlet multinomial regressoin above were obtained using the Maximum a Posteriori (MAP) estimate of the parameters underlying the Dirichlet distributions $\alpha$ values, only the single set of optimal parameters were used, with none of those within the rest of the posterior distribution tested. To confirm that the maps generated via optimisation using MAP, Markov Chain Monte Carlo (MCMC) was used to obtain draws of weights from the posterior distribution. The purpose of this was to be able to obtain chains that had reasonably converged, and then observe whether the habitat maps created using all these weights would generally agree on the presence and distribution of habitats. 

To calculate convergence using the Gelman-Rubin r-hat statistic, $3$ MCMC chains were run simultaneously for both the simplified ($4$) labels and the full set of labels ($24$). The former required $4*19=76$ weights (number of labels $\times$ number of features), and the latter $24*19=456$ weights. Due to the large number of dimensions being explored by the MCMC, the $3$ chains in both cases were not able to fully converge to $1.0$. The weights for the simplified labels were close to convergence, with an r-hat score of $1.065$, although $4$ of the $76$ weights were above $1.2$ ($1.45, 3.53, 1.43, 1.21$). The weights for the full $24$ labels fared considerably worse, with an r-hat score of $1.429$, with only $243$ of the $456$ weights being below $1.1$.

% To select an optimal set of parameters for the dirichlet multinomial, Markov Chain Monte Carlo (MCMC) was used to draw samples from the posterior distribution \todo{(refer to equation?)} over $3,000,000$ runs, with the maximum a posteriori estimate used as the starting value for the weights. To select the single best set of weights from the sequence of chains, every single one was evaluated by being used to do Dirichlet Multinomial regression, where the weights that resulted in the lowest predictive variance (average over all variances) was considered to be the best set of parameters. The weights that corresponded to the lowest average variance also corresponded to the lowest average error compared to the original normalised weights. After the $3,000,000$ runs, the MCMC in both cases (the simplified 24 labels, as well as the full set) was considered to have converged, as the Gelman and Rubin ($\hat{r}$) convergence statistics were calculated to be \todo{(? and ?)}, both very close to the ideal value of $1.0$, Furthermore, for the \todo{24-label case}

% MCMC 2 million runs, 24 labels
% 18-smallest variance corresponds to the 1-smallest error - index 1444288 \\
% 19-smallest variance corresponds to the 2-smallest error - index 1444289 \\
% 20-smallest variance corresponds to the 4-smallest error - index 1444292 \\
% 21-smallest variance corresponds to the 0-smallest error - index 1444291 \\
% 22-smallest variance corresponds to the 3-smallest error - index 1444290 \\

% np.save('data/W_2m_1444288', chains[1444288])
% np.save('data/W_2m_1444289', chains[1444289])
% np.save('data/W_2m_1444292', chains[1444292])
% np.save('data/W_2m_1444291', chains[1444291])
% np.save('data/W_2m_1444290', chains[1444290])

\begin{figure}[H]
    \centerline{\includegraphics{dm4_9m_0_mcmc_weight_hist.pdf}}
    \caption{MCMC weights for 4-label, 19-dimension data case \todo{(need to separate this into separate images, possibly remove axis ticks)}}
    \label{fig:4l-mcmc_weights}
\end{figure}

\begin{figure}[H]
    \centerline{\includegraphics{dm24_950k_0_mcmc_weight_hist.pdf}}
    \caption{MCMC weights for 4-label, 19-dimension data case \todo{(need to separate this into separate images, possibly remove axis ticks)}}
    \label{fig:24l-mcmc_weights}
\end{figure}

